<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Restoration-Guided Kuzushiji Character Recognition Framework under Seal Interference">
  <meta name="keywords" content="RG-KCR, Restoration-Guided Kuzushiji Character Recognition Framework under Seal Interference, Rui-Yang Ju">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RG-KCR</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title" style="font-weight: 600;">Restoration-Guided Kuzushiji Character Recognition Framework under Seal Interference</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ruiyangju.github.io/">Rui-Yang Ju</a>,
              <span>Kohei Yamashita</span>,
              <a href="https://hkmk.github.io/">Hirotaka Kameko</a>,
              <a href="https://www.lsta.media.kyoto-u.ac.jp/mori/author/">Shinsuke Mori</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Kyoto University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="pdf\paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/RuiyangJu/RG-KCR"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://1drv.ms/f/c/56c255dd1bb9ae9e/IgDiLBlaev4XQ46AdIStVkE2Ab97A9c0c9QBD5IabfERfuQ"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-download"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified" style="margin-bottom: 6rem;">
          <img src="./images/fig_pipeline.png" style="display:block; margin:-3rem auto 0 auto; width:100%">
          <h5 class="subtitle has-text-justified" style="margin-top: 15px">
            The pipeline of the proposed restoration-guided Kuzushiji character recognition (RG-KCR) framework consists of three stages: Kuzushiji character detection (Stage 1), Kuzushiji document restoration (Stage 2), and Kuzushiji character classification (Stage 3).
            A training-free document restoration algorithm is introduced in Stage 2 to mitigate seal interference prior to character classification in Stage 3.
          </h5>
        </div>
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified" style="margin-bottom: 6rem;">
          <br>
          <p>
            Kuzushiji was one of the most popular writing styles in pre-modern Japan and was widely used in both personal letters and official documents.
            However, due to its highly cursive forms and extensive glyph variations, most modern Japanese readers cannot directly interpret Kuzushiji characters.
            Therefore, recent research has focused on developing automated Kuzushiji character recognition methods, which have achieved satisfactory performance on relatively clean Kuzushiji document images.
            However, existing methods struggle to maintain recognition accuracy under seal interference (e.g., when seals overlap characters), despite the frequent occurrence of seals in pre-modern Japanese documents.
            To address this challenge, we propose a three-stage restoration-guided Kuzushiji character recognition (RG-KCR) framework specifically designed to mitigate seal interference.
            We also construct datasets for evaluating Kuzushiji character detection (Stage 1) and classification (Stage 3).
            Experimental results show that the YOLOv12-medium model achieves a precision of 98.0% and a recall of 93.3% on the constructed test set.
            We quantitatively evaluate the restoration quality of Stage 2 using PSNR and SSIM.
            In addition, we conduct an ablation study to demonstrate that Stage 2 improves the Top-1 accuracy of Metom, a Vision Transformer (ViT)-based Kuzushiji classifier used in Stage 3, from 93.45% to 95.33%.          </p>
        </div>
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified" style="margin-bottom: 6rem;">
          <img src="./images/fig_intro.png" style="display:block; margin:0 auto; width:100%">
          <br>
          <p>
            To the best of our knowledge, existing Kuzushiji character recognition systems have not explicitly addressed the impact of seal interference, which frequently overlaps with characters and substantially degrades recognition performance.
            We present example recognition results produced by different methods under seal interference.
            The left column shows the input Kuzushiji characters “尚書堂梓”, while the right three columns present the corresponding recognition outputs of three methods: Komonjo Camera (Fuminoha) [TOPPAN Inc., 2023], NDLkotenOCR-Lite [Aoike et al., 2024], and Metom [Imajuku et al., 2024].
            The first row displays the raw document as input, while the second row shows the recognition results after applying our proposed document restoration method.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset</h2>
        <h2 class="title is-4">(1) Data Correction</h2>
        <div class="content has-text-justified" style="margin-bottom: 6rem;">
          <img src="./images/fig_correction.png" style="display:block; margin:0 auto; width:100%">
          <br>
          <p>
            The raw Kuzushiji document images are obtained from the dataset provided by the Center for Open Data in the Humanities (CODH), with source materials preserved by the National Institute of Japanese Literature (NIJL) [NIJL, 2016].
            We select 13 representative documents and exclude pages that contain no Kuzushiji characters, resulting in a final dataset of 1,000 images.
            During the annotation review process, 267 images are found to contain incomplete labels. 
            We manually correct these annotations by adding missing character bounding boxes to improve overall annotation quality.
            We present representative examples of incomplete annotations in the raw dataset, where red boxes denote our manually added annotations and green boxes indicate the original ones.
          </p>
        </div>
        <h2 class="title is-4">(2) Synthetic Data Generation</h2>
        <div class="content has-text-justified" style="margin-bottom: 6rem;">
          <img src="./images/fig_synthetic.png" style="display:block; margin:0 auto; width:100%">
          <br>
          <p>
            Comparison examples between raw (real) Kuzushiji documents and synthetic Kuzushiji documents.
            The seals in the first row are naturally present in the original documents, whereas those in the second row are synthetically added.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiments</h2>
        <h2 class="title is-4">(1) Visual Output of Stage 1</h2>
        <div class="content has-text-justified">
          <img src="./images/fig_yolo12.png" style="display:block; margin:0 auto; width:100%">
          <br>
          <p>
            Examples of qualitative detection results produced by YOLOv12-medium [Tian et al. 2025] on Kuzushiji document images from the constructed dataset.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">(2) Visual Output of Stage 2</h2>
        <div class="content has-text-justified">
          <img src="./images/fig_restoration.png" style="display:block; margin:0 auto; width:100%">
          <br>
          <p>
            Qualitative comparison of restoration results between raw and restored Kuzushiji documents under hyperparameters &tau;<sub>r</sub> = 90 and (&tau;<sub>rg</sub>, &tau;<sub>rb</sub>) = 1.3.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">(3) Visual Final Output</h2>
        <div class="content has-text-justified">
          <img src="./images/fig_final_output.png" style="display:block; margin:0 auto; width:100%">
          <br>
          <p>
            Here are Kuzushiji document images and their corresponding final outputs produced by the proposed RG-KCR framework.
            For visualization, green bounding boxes and the associated modern Japanese characters are overlaid on the documents with a uniform font size of 64 pixels to enhance readability.
            After processing by the RG-KCR framework, readers can intuitively interpret the content of the original Kuzushiji documents.
          </p>
        </div>
      </div>
    </div>
    
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop content">
    <div class="license-block" style="margin-bottom: 1.5em;">
      <img src="./images/CC-BY-SA.png" alt="CC BY-SA 4.0 License" style="vertical-align: middle;">
      This dataset is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" style="margin-left: 8px;">Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)</a>.
    </div>
  </div>
  
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reference</h2>
        <!-- Prop. -->
        <div class="content has-text-justified">
          <p>
            [TOPPAN Inc. 2023] TOPPAN Inc., ふみのは (Fuminoha): 古文書カメラ (Komonjo Camera) (2023), https://camera.fuminoha.jp.
          </p>
          <p>
            [Aoike et al. 2024] Aoike, T., Development of ndlkotenocr-lite, a lightweight ocr that runs at high speed in a cpu environment. In: IPSJ SIG Computers and the Humanities Symposium. pp. 181–186 (2024).
          </p>
          <p>
            [Imajuku et al. 2024] Imajuku, Y., Clanuwat, T.: Metom (2024), https://huggingface.co/SakanaAI/Metom.
          </p>
          <p>
            [NIJL 2016] National Institute of Japanese Literature (国文学研究資料館), Japanese Classical Cursive Script Kuzushiji Dataset（日本古典籍くずし字データセット） (2016), https://doi.org/10.20676/00000340.
          </p>
          <p>
            [Tian et al. 2025] Tian, Y., Ye, Q., Doermann, D., Yolov12: Attention-centric real-time object detectors. In: Advances in Neural Information Processing Systems (2025).
          </p>
        </div>
      </div>
    </div>

  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <strong>If you use our dataset, please cite the paper below:</strong>
      <pre><code>

      </code></pre>
    <strong>The following is the citation of the original Kuzushiji dataset; please cite it when using our benchmark dataset:</strong>
  <pre><code>
  『日本古典籍くずし字データセット』 （国文研所蔵／CODH加工） doi:10.20676/00000340      
  </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The original Kuzushiji dataset used in this work is based on the <strong>『日本古典籍くずし字データセット』</strong> （国文研所蔵／CODH加工）, provided by <a href="https://codh.rois.ac.jp/">ROIS-DS人文学オープンデータ共同利用センター(CODH)</a>,
            which is licensed under the<a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)</a>.
          </p>

          <p>
            All modifications were performed by <strong>Rui-Yang Ju</strong>. 
            This is an independent derivative work and is <strong>not affiliated with or endorsed by the original Kuzushiji dataset authors or their institutions</strong>. 
          </p>
          
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
          </p>
          <p>
            If you have any questions, you can contact me via my <a href="https://ruiyangju.github.io/">homepage</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
